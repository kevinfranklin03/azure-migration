{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92d00bf5-977f-41c4-a078-17d7d3577fab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Bronze → Silver: Orders Transformation\n",
    "\n",
    "## Purpose\n",
    "Transform raw orders data from Bronze layer into clean, validated Silver layer\n",
    "\n",
    "## Transformations Applied\n",
    "1. **Data Quality**: Remove cancelled/unavailable orders\n",
    "2. **Date Features**: Extract year, month, quarter, day of week\n",
    "3. **Delivery Metrics**: Calculate delivery days and late delivery flag\n",
    "4. **Deduplication**: Remove duplicate order_id records\n",
    "5. **Schema Validation**: Ensure correct data types\n",
    "\n",
    "## Input\n",
    "- **Source**: `bronze/olist/orders/oracle_OLIST.OLIST_ORDERS_BASE.parquet`\n",
    "- **Format**: Parquet\n",
    "- **Records**: ~99,441 rows\n",
    "\n",
    "## Output\n",
    "- **Destination**: `silver/orders_clean/`\n",
    "- **Format**: Delta Lake (ACID transactions, time travel)\n",
    "- **Partitioning**: By order_year and order_month\n",
    "- **Expected Records**: ~95,000 rows (after filtering)\n",
    "\n",
    "## Author\n",
    "Kevin\n",
    "\n",
    "## Last Updated\n",
    "Feb 9, 2026\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "209c2fa9-1747-421c-9eeb-655f46333faf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Configuration\n",
    "\n",
    "Set up storage account details and import required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87314b25-2356-4d10-9695-2eec48c923ef",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 3"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported\n✅ Authentication configured\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION & IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "# Import PySpark SQL functions\n",
    "# These are the main transformation functions we'll use\n",
    "from pyspark.sql.functions import (\n",
    "    col,              # Reference columns\n",
    "    year,             # Extract year from date\n",
    "    month,            # Extract month from date\n",
    "    quarter,          # Extract quarter from date\n",
    "    dayofweek,        # Extract day of week (1=Sunday, 7=Saturday)\n",
    "    datediff,         # Calculate days between two dates\n",
    "    when,             # Conditional logic (IF-THEN-ELSE)\n",
    "    current_timestamp,# Get current timestamp for auditing\n",
    "    count,            # Count rows\n",
    "    min,              # Get minimum value\n",
    "    max,              # Get maximum value\n",
    "    avg,              # Calculate average\n",
    "    sum               # Calculate sum\n",
    ")\n",
    "\n",
    "# Import Delta Lake functionality\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Storage account name\n",
    "storage_account_name = \"stgolistmigration\"\n",
    "\n",
    "\n",
    "account_key = \"\"\n",
    "\n",
    "# Configure Spark authentication\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{storage_account_name}.dfs.core.windows.net\",\n",
    "    account_key\n",
    ")\n",
    "\n",
    "print(\"✅ Libraries imported\")\n",
    "print(\"✅ Authentication configured\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f655b75e-76ac-4111-a0ba-6ff8765ebb47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# HELPER FUNCTIONS - PATH BUILDERS\n",
    "# =============================================================================\n",
    "\n",
    "def get_bronze_path(table_folder, filename):\n",
    "    \"\"\"\n",
    "    Build full path to bronze layer data\n",
    "    \n",
    "    Args:\n",
    "        table_folder (str): Folder name (e.g., 'orders', 'customers')\n",
    "        filename (str): Parquet file name\n",
    "    \n",
    "    Returns:\n",
    "        str: Full ABFSS path to bronze data\n",
    "    \n",
    "    Example:\n",
    "        get_bronze_path(\"orders\", \"oracle_OLIST.OLIST_ORDERS_BASE.parquet\")\n",
    "        → \"abfss://bronze@stgolistmigration.dfs.core.windows.net/olist/orders/oracle_OLIST.OLIST_ORDERS_BASE.parquet\"\n",
    "    \"\"\"\n",
    "    return f\"abfss://bronze@{storage_account_name}.dfs.core.windows.net/olist/{table_folder}/{filename}\"\n",
    "\n",
    "\n",
    "def get_silver_path(table_name):\n",
    "    \"\"\"\n",
    "    Build full path to silver layer data\n",
    "    \n",
    "    Args:\n",
    "        table_name (str): Table name (e.g., 'orders_clean')\n",
    "    \n",
    "    Returns:\n",
    "        str: Full ABFSS path to silver data\n",
    "    \n",
    "    Example:\n",
    "        get_silver_path(\"orders_clean\")\n",
    "        → \"abfss://silver@stgolistmigration.dfs.core.windows.net/orders_clean/\"\n",
    "    \"\"\"\n",
    "    return f\"abfss://silver@{storage_account_name}.dfs.core.windows.net/{table_name}/\"\n",
    "\n",
    "\n",
    "def get_gold_path(table_name):\n",
    "    \"\"\"\n",
    "    Build full path to gold layer data\n",
    "    \n",
    "    Args:\n",
    "        table_name (str): Table name (e.g., 'fact_orders')\n",
    "    \n",
    "    Returns:\n",
    "        str: Full ABFSS path to gold data\n",
    "    \"\"\"\n",
    "    return f\"abfss://gold@{storage_account_name}.dfs.core.windows.net/{table_name}/\"\n",
    "\n",
    "\n",
    "print(\"✅ Helper functions defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc23d8bf-a2e4-4958-ad2c-56bc76069983",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 1: Read Bronze Data\n",
    "\n",
    "Load raw orders data from Bronze layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0b0fb49-0dc4-44f6-9813-3caa1d99a408",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Untitled"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCD6 Reading bronze data from:\n   abfss://bronze@stgolistmigration.dfs.core.windows.net/olist/orders/oracle_OLIST.OLIST_ORDERS_BASE.parquet\n================================================================================\n✅ Bronze data loaded successfully\n   Total rows: 99,441\n   Total columns: 8\n================================================================================\n\n\uD83D\uDCCA Sample bronze data (first 3 rows):\n-RECORD 0---------------------------------------------------------\n ORDER_ID                      | e5fa5a7210941f7d56d0208e4e071d35 \n CUSTOMER_ID                   | 683c54fc24d40ee9f8a6fc179fd9856c \n ORDER_STATUS                  | canceled                         \n ORDER_PURCHASE_TIMESTAMP      | 2016-09-05 00:15:34              \n ORDER_APPROVED_AT             | 2016-10-07 13:17:15              \n ORDER_DELIVERED_CARRIER_DATE  | NULL                             \n ORDER_DELIVERED_CUSTOMER_DATE | NULL                             \n ORDER_ESTIMATED_DELIVERY_DATE | 2016-10-28 00:00:00              \n-RECORD 1---------------------------------------------------------\n ORDER_ID                      | 2e7a8482f6fb09756ca50c10d7bfc047 \n CUSTOMER_ID                   | 08c5351a6aca1c1589a38f244edeee9d \n ORDER_STATUS                  | shipped                          \n ORDER_PURCHASE_TIMESTAMP      | 2016-09-04 21:15:19              \n ORDER_APPROVED_AT             | 2016-10-07 13:18:03              \n ORDER_DELIVERED_CARRIER_DATE  | 2016-10-18 13:14:51              \n ORDER_DELIVERED_CUSTOMER_DATE | NULL                             \n ORDER_ESTIMATED_DELIVERY_DATE | 2016-10-20 00:00:00              \n-RECORD 2---------------------------------------------------------\n ORDER_ID                      | 809a282bbd5dbcabb6f2f724fca862ec \n CUSTOMER_ID                   | 622e13439d6b5a0b486c435618b2679e \n ORDER_STATUS                  | canceled                         \n ORDER_PURCHASE_TIMESTAMP      | 2016-09-13 15:24:19              \n ORDER_APPROVED_AT             | 2016-10-07 13:16:46              \n ORDER_DELIVERED_CARRIER_DATE  | NULL                             \n ORDER_DELIVERED_CUSTOMER_DATE | NULL                             \n ORDER_ESTIMATED_DELIVERY_DATE | 2016-09-30 00:00:00              \n\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: READ BRONZE DATA\n",
    "# =============================================================================\n",
    "\n",
    "# Construct path to bronze orders data\n",
    "# This is the raw data extracted from Oracle database\n",
    "bronze_orders_path = get_bronze_path(\"orders\", \"oracle_OLIST.OLIST_ORDERS_BASE.parquet\")\n",
    "\n",
    "print(f\"\uD83D\uDCD6 Reading bronze data from:\")\n",
    "print(f\"   {bronze_orders_path}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Read parquet file into DataFrame\n",
    "# spark.read.parquet() is optimized for columnar data\n",
    "# DataFrame is an immutable distributed collection of data\n",
    "df_orders_bronze = spark.read.parquet(bronze_orders_path)\n",
    "\n",
    "# Get record count\n",
    "# .count() is an ACTION that triggers computation\n",
    "bronze_count = df_orders_bronze.count()\n",
    "\n",
    "print(f\"✅ Bronze data loaded successfully\")\n",
    "print(f\"   Total rows: {bronze_count:,}\")\n",
    "print(f\"   Total columns: {len(df_orders_bronze.columns)}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Display sample records\n",
    "# .show() displays data in tabular format\n",
    "# truncate=False shows full column values\n",
    "# vertical=True shows one column per line (easier to read)\n",
    "print(\"\\n\uD83D\uDCCA Sample bronze data (first 3 rows):\")\n",
    "df_orders_bronze.limit(3).show(truncate=False, vertical=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1923ed98-82b8-49c4-8434-6227d1984567",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Untitled"
    }
   },
   "source": [
    "## Step 2: Data Quality Analysis\n",
    "\n",
    "Inspect data quality issues before transformation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41fb6953-fb73-4eb3-9f88-67f513cc037f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Untitled"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD0D Data Quality Analysis\n================================================================================\n\n1️⃣ NULL VALUE ANALYSIS:\n--------------------------------------------------------------------------------\n-RECORD 0-----------------------------\n ORDER_ID                      | 0    \n CUSTOMER_ID                   | 0    \n ORDER_STATUS                  | 0    \n ORDER_PURCHASE_TIMESTAMP      | 0    \n ORDER_APPROVED_AT             | 160  \n ORDER_DELIVERED_CARRIER_DATE  | 1783 \n ORDER_DELIVERED_CUSTOMER_DATE | 2965 \n ORDER_ESTIMATED_DELIVERY_DATE | 0    \n\n\n2️⃣ ORDER STATUS DISTRIBUTION:\n--------------------------------------------------------------------------------\n+------------+-----+\n|order_status|count|\n+------------+-----+\n|delivered   |96478|\n|shipped     |1107 |\n|canceled    |625  |\n|unavailable |609  |\n|invoiced    |314  |\n|processing  |301  |\n|created     |5    |\n|approved    |2    |\n+------------+-----+\n\n\n3️⃣ DATE RANGE ANALYSIS:\n--------------------------------------------------------------------------------\n+-------------------+-------------------+\n|earliest_order     |latest_order       |\n+-------------------+-------------------+\n|2016-09-04 21:15:19|2018-10-17 17:30:18|\n+-------------------+-------------------+\n\n\n4️⃣ DUPLICATE ANALYSIS:\n--------------------------------------------------------------------------------\nTotal rows: 99,441\nUnique order_ids: 99,441\nDuplicate records: 0\n✅ No duplicates found\n================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: DATA QUALITY ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\uD83D\uDD0D Data Quality Analysis\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# -------------------------\n",
    "# Check 1: Null Values\n",
    "# -------------------------\n",
    "print(\"\\n1️⃣ NULL VALUE ANALYSIS:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# For each column, count how many null values exist\n",
    "# when(condition, value) returns value if condition is true\n",
    "# col(c).isNull() checks if column has null value\n",
    "null_counts = df_orders_bronze.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c) \n",
    "    for c in df_orders_bronze.columns\n",
    "])\n",
    "\n",
    "# Display as transposed table (easier to read)\n",
    "null_counts.show(vertical=True, truncate=False)\n",
    "\n",
    "# -------------------------\n",
    "# Check 2: Order Status Distribution\n",
    "# -------------------------\n",
    "print(\"\\n2️⃣ ORDER STATUS DISTRIBUTION:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Group by order_status and count occurrences\n",
    "# This shows which statuses exist and how common they are\n",
    "df_orders_bronze.groupBy(\"order_status\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show(truncate=False)\n",
    "\n",
    "# -------------------------\n",
    "# Check 3: Date Range Analysis\n",
    "# -------------------------\n",
    "print(\"\\n3️⃣ DATE RANGE ANALYSIS:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Find earliest and latest order dates\n",
    "# This helps understand the time span of the data\n",
    "date_summary = df_orders_bronze.select(\n",
    "    min(\"order_purchase_timestamp\").alias(\"earliest_order\"),\n",
    "    max(\"order_purchase_timestamp\").alias(\"latest_order\")\n",
    ")\n",
    "\n",
    "date_summary.show(truncate=False)\n",
    "\n",
    "# -------------------------\n",
    "# Check 4: Duplicate Check\n",
    "# -------------------------\n",
    "print(\"\\n4️⃣ DUPLICATE ANALYSIS:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Count total rows vs unique order_ids\n",
    "# If different, we have duplicates\n",
    "total_rows = df_orders_bronze.count()\n",
    "unique_orders = df_orders_bronze.select(\"order_id\").distinct().count()\n",
    "duplicates = total_rows - unique_orders\n",
    "\n",
    "print(f\"Total rows: {total_rows:,}\")\n",
    "print(f\"Unique order_ids: {unique_orders:,}\")\n",
    "print(f\"Duplicate records: {duplicates:,}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"⚠️  Duplicates found - will remove in transformation\")\n",
    "else:\n",
    "    print(\"✅ No duplicates found\")\n",
    "\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30cbc544-611e-4c79-bc5a-f0250bea7357",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Untitled"
    }
   },
   "source": [
    "## Step 3: Apply Transformations\n",
    "\n",
    "Clean and enrich the orders data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37c604f2-b985-4c92-a386-12ff8385d763",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 10"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD04 Applying transformations...\n================================================================================\n✅ Transformations complete\n   Silver rows: 98,200\n   Removed: 1,241 rows (1.2%)\n================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: APPLY TRANSFORMATIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\uD83D\uDD04 Applying transformations...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Start with bronze DataFrame\n",
    "# Each transformation returns a new DataFrame (DataFrames are immutable)\n",
    "df_orders_silver = df_orders_bronze \\\n",
    "    .filter(\n",
    "        # TRANSFORMATION 1: Filter out invalid order statuses\n",
    "        # Only keep orders that were successfully processed\n",
    "        # .isin() checks if value is in the list\n",
    "        col(\"order_status\").isin([\"delivered\", \"shipped\", \"processing\", \"invoiced\"])\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        # TRANSFORMATION 2: Extract year from purchase timestamp\n",
    "        # year() function extracts the year component\n",
    "        # This is useful for time-based analysis and partitioning\n",
    "        \"order_year\",\n",
    "        year(col(\"order_purchase_timestamp\"))\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        # TRANSFORMATION 3: Extract month (1-12)\n",
    "        \"order_month\",\n",
    "        month(col(\"order_purchase_timestamp\"))\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        # TRANSFORMATION 4: Extract quarter (1-4)\n",
    "        # Q1 = Jan-Mar, Q2 = Apr-Jun, Q3 = Jul-Sep, Q4 = Oct-Dec\n",
    "        \"order_quarter\",\n",
    "        quarter(col(\"order_purchase_timestamp\"))\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        # TRANSFORMATION 5: Extract day of week\n",
    "        # 1 = Sunday, 2 = Monday, ..., 7 = Saturday\n",
    "        # Useful for analyzing weekly patterns\n",
    "        \"order_day_of_week\",\n",
    "        dayofweek(col(\"order_purchase_timestamp\"))\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        # TRANSFORMATION 6: Calculate delivery time in days\n",
    "        # datediff() calculates days between two dates\n",
    "        # This measures how long delivery took\n",
    "        \"delivery_days\",\n",
    "        datediff(\n",
    "            col(\"order_delivered_customer_date\"),\n",
    "            col(\"order_purchase_timestamp\")\n",
    "        )\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        # TRANSFORMATION 7: Calculate difference between estimated and actual delivery\n",
    "        # Positive number = late delivery\n",
    "        # Negative number = early delivery\n",
    "        \"estimated_vs_actual_delivery_diff\",\n",
    "        datediff(\n",
    "            col(\"order_delivered_customer_date\"),\n",
    "            col(\"order_estimated_delivery_date\")\n",
    "        )\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        # TRANSFORMATION 8: Create boolean flag for late deliveries\n",
    "        # when() is like IF-THEN-ELSE\n",
    "        # True if delivered after estimated date, False otherwise\n",
    "        \"is_late_delivery\",\n",
    "        when(col(\"estimated_vs_actual_delivery_diff\") > 0, True).otherwise(False)\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        # TRANSFORMATION 9: Add ingestion timestamp for auditing\n",
    "        # Records when this row was processed into Silver layer\n",
    "        # Useful for tracking data lineage and debugging\n",
    "        \"ingestion_timestamp\",\n",
    "        current_timestamp()\n",
    "    ) \\\n",
    "    .dropDuplicates(\n",
    "        # TRANSFORMATION 10: Remove duplicate order_ids\n",
    "        # Keeps the first occurrence of each order_id\n",
    "        [\"order_id\"]\n",
    "    )\n",
    "\n",
    "# Get transformed record count\n",
    "silver_count = df_orders_silver.count()\n",
    "removed_count = bronze_count - silver_count\n",
    "\n",
    "print(f\"✅ Transformations complete\")\n",
    "print(f\"   Silver rows: {silver_count:,}\")\n",
    "print(f\"   Removed: {removed_count:,} rows ({removed_count/bronze_count*100:.1f}%)\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6310739-0cca-4b73-bd84-aee5e4fdc094",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 11"
    }
   },
   "source": [
    "## Step 4: Validate Transformed Data\n",
    "\n",
    "Verify data quality after transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7bf4e8e-5913-4b38-a4c0-17fcd76c68f2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 12"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Silver Layer Quality Metrics\n================================================================================\n\n\uD83D\uDCCA RECORD COUNT:\n   Total Orders: 98,200\n\n\uD83D\uDCC5 DATE RANGE:\n   From: 2016-09-04 21:15:19\n   To: 2018-09-03 09:06:57\n\n\uD83D\uDE9A DELIVERY METRICS:\n   Late Deliveries: 6,534\n   Avg Delivery Days: 12.5\n   Min Delivery Days: 0\n   Max Delivery Days: 210\n\n\uD83D\uDCC8 ORDERS BY YEAR-MONTH:\n+----------+-----------+-----+\n|order_year|order_month|count|\n+----------+-----------+-----+\n|2016      |9          |2    |\n|2016      |10         |293  |\n|2016      |12         |1    |\n|2017      |1          |787  |\n|2017      |2          |1717 |\n|2017      |3          |2617 |\n|2017      |4          |2376 |\n|2017      |5          |3640 |\n|2017      |6          |3205 |\n|2017      |7          |3946 |\n|2017      |8          |4272 |\n|2017      |9          |4227 |\n|2017      |10         |4547 |\n|2017      |11         |7421 |\n|2017      |12         |5618 |\n|2018      |1          |7187 |\n|2018      |2          |6624 |\n|2018      |3          |7168 |\n|2018      |4          |6919 |\n|2018      |5          |6833 |\n+----------+-----------+-----+\nonly showing top 20 rows\n================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 4: VALIDATE TRANSFORMED DATA\n",
    "# =============================================================================\n",
    "\n",
    "print(\"✅ Silver Layer Quality Metrics\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Metric 1: Record count\n",
    "print(f\"\\n\uD83D\uDCCA RECORD COUNT:\")\n",
    "print(f\"   Total Orders: {df_orders_silver.count():,}\")\n",
    "\n",
    "# Metric 2: Date range\n",
    "print(f\"\\n\uD83D\uDCC5 DATE RANGE:\")\n",
    "date_range = df_orders_silver.agg(\n",
    "    min('order_purchase_timestamp').alias(\"min_date\"),\n",
    "    max('order_purchase_timestamp').alias(\"max_date\")\n",
    ").collect()[0]\n",
    "print(f\"   From: {date_range['min_date']}\")\n",
    "print(f\"   To: {date_range['max_date']}\")\n",
    "\n",
    "# Metric 3: Delivery metrics\n",
    "print(f\"\\n\uD83D\uDE9A DELIVERY METRICS:\")\n",
    "delivery_metrics = df_orders_silver.agg(\n",
    "    count(when(col('is_late_delivery') == True, 1)).alias(\"late_deliveries\"),\n",
    "    avg('delivery_days').alias(\"avg_delivery_days\"),\n",
    "    min('delivery_days').alias(\"min_delivery_days\"),\n",
    "    max('delivery_days').alias(\"max_delivery_days\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"   Late Deliveries: {delivery_metrics['late_deliveries']:,}\")\n",
    "print(f\"   Avg Delivery Days: {delivery_metrics['avg_delivery_days']:.1f}\")\n",
    "print(f\"   Min Delivery Days: {delivery_metrics['min_delivery_days']}\")\n",
    "print(f\"   Max Delivery Days: {delivery_metrics['max_delivery_days']}\")\n",
    "\n",
    "# Metric 4: Year/Month distribution\n",
    "print(f\"\\n\uD83D\uDCC8 ORDERS BY YEAR-MONTH:\")\n",
    "df_orders_silver.groupBy(\"order_year\", \"order_month\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"order_year\", \"order_month\") \\\n",
    "    .show(20, truncate=False)\n",
    "\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d829b931-c5db-4106-bd76-1c820bf0536b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 13"
    }
   },
   "source": [
    "## Step 5: Write to Silver Layer\n",
    "\n",
    "Save transformed data as Delta Lake table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f112396-7850-4dbf-b6b0-c177087ef2f1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Untitled"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCBE Writing to Silver layer...\n   Path: abfss://silver@stgolistmigration.dfs.core.windows.net/orders_clean/\n================================================================================\n✅ Silver layer written successfully\n   Format: Delta Lake\n   Partitioning: order_year, order_month\n================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 5: WRITE TO SILVER LAYER (DELTA FORMAT)\n",
    "# =============================================================================\n",
    "\n",
    "# Define output path\n",
    "output_path = get_silver_path(\"orders_clean\")\n",
    "\n",
    "print(f\"\uD83D\uDCBE Writing to Silver layer...\")\n",
    "print(f\"   Path: {output_path}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Write as Delta Lake table\n",
    "# Delta Lake provides:\n",
    "# - ACID transactions\n",
    "# - Time travel (query historical versions)\n",
    "# - Schema enforcement\n",
    "# - Faster queries than Parquet\n",
    "df_orders_silver.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .partitionBy(\"order_year\", \"order_month\") \\\n",
    "    .save(output_path)\n",
    "\n",
    "print(f\"✅ Silver layer written successfully\")\n",
    "print(f\"   Format: Delta Lake\")\n",
    "print(f\"   Partitioning: order_year, order_month\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bcb21523-a781-4217-a0f4-35b7b8b5dc49",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 15"
    }
   },
   "source": [
    "## Step 6: Verify Silver Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71de1023-bac3-41a5-a0fa-bfb3e7c4803b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 16"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCBE Writing to Silver layer...\n   Path: abfss://silver@stgolistmigration.dfs.core.windows.net/orders_clean/\n================================================================================\n✅ Data written to Silver\n   Format: Delta Lake\n   Partitioned by: order_year, order_month\n================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Write to Silver Layer\n",
    "output_path = get_silver_path(\"orders_clean\")\n",
    "\n",
    "print(f\"\uD83D\uDCBE Writing to Silver layer...\")\n",
    "print(f\"   Path: {output_path}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Write as Delta format\n",
    "df_orders_silver.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .partitionBy(\"order_year\", \"order_month\") \\\n",
    "    .save(output_path)\n",
    "\n",
    "print(f\"✅ Data written to Silver\")\n",
    "print(f\"   Format: Delta Lake\")\n",
    "print(f\"   Partitioned by: order_year, order_month\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26abdf5d-901c-4820-9c68-aa89d9902ae0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 17"
    }
   },
   "source": [
    "## Step 7: Verify Silver Data\n",
    "\n",
    "Query the Delta table to verify it was created correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ed3703e-1146-4dd9-91fd-f6cd096395ec",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 18"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD0D Verifying Silver layer...\n================================================================================\n✅ Silver data readable\n   Total rows: 98,200\n   Columns: 16\n\n\uD83D\uDCCA Orders by Year-Month:\n+----------+-----------+------+------------------+---------------+\n|order_year|order_month|orders|avg_delivery      |late_deliveries|\n+----------+-----------+------+------------------+---------------+\n|2016      |9          |2     |55.0              |1              |\n|2016      |10         |293   |19.633962264150945|2              |\n|2016      |12         |1     |5.0               |0              |\n|2017      |1          |787   |12.753333333333334|22             |\n|2017      |2          |1717  |13.300060496067756|49             |\n|2017      |3          |2617  |13.044383346425766|116            |\n|2017      |4          |2376  |15.02301346070343 |151            |\n|2017      |5          |3640  |11.427080394922426|106            |\n|2017      |6          |3205  |12.012759170653908|95             |\n|2017      |7          |3946  |11.488894628099173|108            |\n|2017      |8          |4272  |11.016455998092058|122            |\n|2017      |9          |4227  |11.722650602409638|182            |\n|2017      |10         |4547  |11.733139794551139|187            |\n|2017      |11         |7421  |15.073133918770582|904            |\n|2017      |12         |5618  |15.30564121168148 |411            |\n|2018      |1          |7187  |14.005799971707455|403            |\n|2018      |2          |6624  |16.87337909992372 |926            |\n|2018      |3          |7168  |16.23761245180637 |1328           |\n|2018      |4          |6919  |11.419388055310385|306            |\n|2018      |5          |6833  |11.336494295451178|443            |\n+----------+-----------+------+------------------+---------------+\nonly showing top 20 rows\n\n\uD83D\uDCCB Sample records:\n-RECORD 0-------------------------------------------------------------\n ORDER_ID                          | b626a11507dbce56f74a5b1b1a6af615 \n CUSTOMER_ID                       | fd5878d884704e7165c352d83b9cadb7 \n ORDER_STATUS                      | delivered                        \n ORDER_PURCHASE_TIMESTAMP          | 2017-01-23 22:29:40              \n ORDER_APPROVED_AT                 | 2017-01-23 22:41:58              \n ORDER_DELIVERED_CARRIER_DATE      | 2017-01-24 08:19:20              \n ORDER_DELIVERED_CUSTOMER_DATE     | 2017-01-27 11:34:04              \n ORDER_ESTIMATED_DELIVERY_DATE     | 2017-02-28 00:00:00              \n order_year                        | 2017                             \n order_month                       | 1                                \n order_quarter                     | 1                                \n order_day_of_week                 | 2                                \n delivery_days                     | 4                                \n estimated_vs_actual_delivery_diff | -32                              \n is_late_delivery                  | false                            \n ingestion_timestamp               | 2026-02-09 12:35:21.00911        \n-RECORD 1-------------------------------------------------------------\n ORDER_ID                          | f313be47c42e07616027ad6d6ac3034c \n CUSTOMER_ID                       | 1df2dcecdf59a9ec5bbd2f877821219e \n ORDER_STATUS                      | delivered                        \n ORDER_PURCHASE_TIMESTAMP          | 2017-01-12 13:11:45              \n ORDER_APPROVED_AT                 | 2017-01-12 13:24:45              \n ORDER_DELIVERED_CARRIER_DATE      | 2017-01-13 15:52:27              \n ORDER_DELIVERED_CUSTOMER_DATE     | 2017-01-26 14:03:59              \n ORDER_ESTIMATED_DELIVERY_DATE     | 2017-02-22 00:00:00              \n order_year                        | 2017                             \n order_month                       | 1                                \n order_quarter                     | 1                                \n order_day_of_week                 | 5                                \n delivery_days                     | 14                               \n estimated_vs_actual_delivery_diff | -27                              \n is_late_delivery                  | false                            \n ingestion_timestamp               | 2026-02-09 12:35:21.00911        \n-RECORD 2-------------------------------------------------------------\n ORDER_ID                          | d9515cd3ca09c7b9b751f077d2adfc84 \n CUSTOMER_ID                       | 47e2de6eab3618c1d08f51f6d3af4826 \n ORDER_STATUS                      | delivered                        \n ORDER_PURCHASE_TIMESTAMP          | 2017-01-30 17:05:18              \n ORDER_APPROVED_AT                 | 2017-02-01 04:35:07              \n ORDER_DELIVERED_CARRIER_DATE      | 2017-02-13 15:25:39              \n ORDER_DELIVERED_CUSTOMER_DATE     | 2017-02-20 13:34:04              \n ORDER_ESTIMATED_DELIVERY_DATE     | 2017-03-10 00:00:00              \n order_year                        | 2017                             \n order_month                       | 1                                \n order_quarter                     | 1                                \n order_day_of_week                 | 2                                \n delivery_days                     | 21                               \n estimated_vs_actual_delivery_diff | -18                              \n is_late_delivery                  | false                            \n ingestion_timestamp               | 2026-02-09 12:35:21.00911        \n\n================================================================================\n\uD83C\uDF89 Orders Bronze → Silver complete!\n"
     ]
    }
   ],
   "source": [
    "# Verify data was written successfully\n",
    "print(\"\uD83D\uDD0D Verifying Silver layer...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Read back from the Delta path\n",
    "output_path = get_silver_path(\"orders_clean\")\n",
    "df_verify = spark.read.format(\"delta\").load(output_path)\n",
    "\n",
    "print(f\"✅ Silver data readable\")\n",
    "print(f\"   Total rows: {df_verify.count():,}\")\n",
    "print(f\"   Columns: {len(df_verify.columns)}\")\n",
    "\n",
    "# Show summary by year/month\n",
    "print(\"\\n\uD83D\uDCCA Orders by Year-Month:\")\n",
    "df_verify.groupBy(\"order_year\", \"order_month\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"orders\"),\n",
    "        avg(\"delivery_days\").alias(\"avg_delivery\"),\n",
    "        sum(when(col(\"is_late_delivery\"), 1).otherwise(0)).alias(\"late_deliveries\")\n",
    "    ) \\\n",
    "    .orderBy(\"order_year\", \"order_month\") \\\n",
    "    .show(20, truncate=False)\n",
    "\n",
    "# Show sample records\n",
    "print(\"\\n\uD83D\uDCCB Sample records:\")\n",
    "df_verify.limit(3).show(truncate=False, vertical=True)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"\uD83C\uDF89 Orders Bronze → Silver complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_bronze_to_silver_orders",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}